{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\iechi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\iechi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\iechi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from preprocess import filter_pos, process_text, remove_nt, lemma_pattern, lemmatize_word, adv_to_adj\n",
    "from vader import get_sentiment\n",
    "from pain_points import get_frequent, get_negative_tokens, create_token_match_columns, process_token_df\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pycommon.warehouse.load_queries import acquire_all_review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquire all review data with skip and limit types: <class 'NoneType'> <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "#port = os.getenv(\"MONGO_PORT\") if os.getenv(\"MONGO_PORT\") is not None else 27017 # MONGO_PORT defines the port number. \n",
    "port= 27017\n",
    "mongo_client = MongoClient('localhost', port) # mongo is always the host. Again, docker handles this dns resolution.\n",
    "\n",
    "# And we're good! mongo is ready to be used. Most of the methods in pycommon/warehouse need you to \n",
    "# pass in the mongoclient. \n",
    "\n",
    "reviews = acquire_all_review_data(\n",
    "        mongo_client, \n",
    "        datetime.datetime(2001,12,1,0,0).timestamp(), # from\n",
    "        datetime.datetime(2018,12,1,0,0).timestamp(), # to\n",
    "        \"SimpangAsia\",\n",
    "        \"Yelp\"\n",
    "    )\n",
    "\n",
    "reviews_array = []\n",
    "for review in reviews:\n",
    "    reviews_array.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"timestamp\": [reviews_array[i].timestamp for i in range(0,len(reviews_array))],\n",
    "    \"source_id\": [reviews_array[i].source_id for i in range(0,len(reviews_array))],\n",
    "    \"business_id\": [reviews_array[i].business_id for i in range(0,len(reviews_array))],\n",
    "    \"review_content\": [reviews_array[i].content for i in range(0,len(reviews_array))],\n",
    "    \"review_rating\": [reviews_array[i].rating for i in range(0,len(reviews_array))],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retains only adjectives and adverbs for reviews\n",
    "df['review_tokens'] = df['review_content'].apply(filter_pos)\n",
    "# Makes lowercase, removes punctuation and stopwords, and lemmatizes remaining words\n",
    "df['review_tokens'] = df['review_tokens'].apply(process_text)\n",
    "# removes the word 'nt'\n",
    "df['review_tokens'] = df['review_tokens'].apply(remove_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting tokens\n",
    "most_freq = get_frequent(df['review_tokens'],500)\n",
    "neg_corp = get_negative_tokens(most_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iechi\\Desktop\\Files\\Work\\Coding Projects\\BBB\\src\\nlp\\pain_points.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  token_df['neg_sentence'] = token_df['review_content'].apply(lambda x: get_neg_sentence(neg_token_list[index], x))\n",
      "C:\\Users\\iechi\\Desktop\\Files\\Work\\Coding Projects\\BBB\\src\\nlp\\pain_points.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  token_df.dropna(inplace=True)\n",
      "C:\\Users\\iechi\\Desktop\\Files\\Work\\Coding Projects\\BBB\\src\\nlp\\pain_points.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  token_df['df_len'] = len(token_df)\n",
      "C:\\Users\\iechi\\Desktop\\Files\\Work\\Coding Projects\\BBB\\src\\nlp\\pain_points.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  token_df['token'] = neg_token_list[index]\n"
     ]
    }
   ],
   "source": [
    "create_token_match_columns(neg_corp, df)\n",
    "token_df = process_token_df(neg_corp, df)\n",
    "token_df.sort_values(['df_len','token'], ascending = False, inplace=True)\n",
    "token_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.drop(neg_corp, axis=1, inplace=True)\n",
    "token_df.drop(['level_0', 'index','review_content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_tokens</th>\n",
       "      <th>neg_sentence</th>\n",
       "      <th>df_len</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>SimpangAsia</td>\n",
       "      <td>5</td>\n",
       "      <td>first everlasting Indonesia Malaysia happy yum...</td>\n",
       "      <td>It's insanely spicy! I felt the fire in my mo...</td>\n",
       "      <td>48</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>SimpangAsia</td>\n",
       "      <td>5</td>\n",
       "      <td>favorite first new subsequent locality bad eas...</td>\n",
       "      <td>Let's start with the bad: parking</td>\n",
       "      <td>48</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>SimpangAsia</td>\n",
       "      <td>4</td>\n",
       "      <td>great thorough tender bad fast hot enough odd ...</td>\n",
       "      <td>The bad side is that some dishes came out ver...</td>\n",
       "      <td>48</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>SimpangAsia</td>\n",
       "      <td>1</td>\n",
       "      <td>worst ever bad thorough mild extra hot true le...</td>\n",
       "      <td>very bad services and food is not good</td>\n",
       "      <td>48</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>Yelp</td>\n",
       "      <td>SimpangAsia</td>\n",
       "      <td>1</td>\n",
       "      <td>absolute horrible sure easier bland reasonable...</td>\n",
       "      <td>It was so bad, he filed a report with the LA ...</td>\n",
       "      <td>48</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp source_id  business_id  review_rating  \\\n",
       "0 2018-08-06      Yelp  SimpangAsia              5   \n",
       "1 2017-10-01      Yelp  SimpangAsia              5   \n",
       "2 2017-12-07      Yelp  SimpangAsia              4   \n",
       "3 2018-11-07      Yelp  SimpangAsia              1   \n",
       "4 2016-06-11      Yelp  SimpangAsia              1   \n",
       "\n",
       "                                       review_tokens  \\\n",
       "0  first everlasting Indonesia Malaysia happy yum...   \n",
       "1  favorite first new subsequent locality bad eas...   \n",
       "2  great thorough tender bad fast hot enough odd ...   \n",
       "3  worst ever bad thorough mild extra hot true le...   \n",
       "4  absolute horrible sure easier bland reasonable...   \n",
       "\n",
       "                                        neg_sentence  df_len token  \n",
       "0   It's insanely spicy! I felt the fire in my mo...      48   bad  \n",
       "1                  Let's start with the bad: parking      48   bad  \n",
       "2   The bad side is that some dishes came out ver...      48   bad  \n",
       "3             very bad services and food is not good      48   bad  \n",
       "4   It was so bad, he filed a report with the LA ...      48   bad  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try to use Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\iechi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = token_df['neg_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.DataFrame(topic, columns=['neg_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(x):\n",
    "    return process_text(x).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = topic_df['neg_sentence'].map(process_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [insane, spicy, feel, fire, mouth, till, next,...\n",
       "1                                [let, start, bad, park]\n",
       "2             [bad, side, dish, come, fast, hot, enough]\n",
       "3                         [bad, service, food, thorough]\n",
       "4      [bad, file, report, la, department, public, he...\n",
       "5      [bad, eventual, live, culver, three, year, try...\n",
       "6      [know, anythe, yelp, review, primary, goal, si...\n",
       "7                            [kid, hungry, grubhub, bad]\n",
       "8                                        [e, teler, bad]\n",
       "9            [bad, service, horrible, operation, period]\n",
       "10     [high, rave, yelp, fail, take, consideration, ...\n",
       "11     [one, bad, change, cant, order, nasi, goreng, ...\n",
       "12     [omg, three, hour, subsequent, give, true, bad...\n",
       "13                             [way, slow, bad, service]\n",
       "14                                           [bad, Asia]\n",
       "15     [somethe, say, almost, drop, fork, spoon, take...\n",
       "16     [fourth, food, awful, get, date, padang, sioma...\n",
       "17                        [thorough, food, bad, service]\n",
       "18              [bad, dont, another, branch, san, diego]\n",
       "19     [mean, say, true, bad, first, time, experience...\n",
       "20     [bad, find, strand, hair, soup, kind, make, lo...\n",
       "21            [tempeh, okay, bad, decided, considerable]\n",
       "22                      [multiple, job, kind, feel, bad]\n",
       "23                            [stomach, hurt, bad, food]\n",
       "24     [first, bad, lot, tend, fill, reasonable, prom...\n",
       "25                                [bad, live, far, away]\n",
       "26                         [bad, indo, food, san, diego]\n",
       "27     [country, outlaw, durian, public, place, even,...\n",
       "28                                       [id, bad, sure]\n",
       "29     [like, Thai, food, beta, test, Indonesia, food...\n",
       "                             ...                        \n",
       "299    [pocky, dip, dark, chocolate, insane, turn, ba...\n",
       "300                       [disgust, word, moist, though]\n",
       "301                     [shake, thorough, boba, disgust]\n",
       "302    [filthy, state, bathroom, recent, visit, many,...\n",
       "303            [second, time, disgust, deserve, 1, star]\n",
       "304                                 [happen, damn, time]\n",
       "305                         [probable, since, damn, far]\n",
       "306    [yeah, yeah, sound, nasty, ever, suck, cartila...\n",
       "307    [life, know, Indonesia, food, damn, thorough, ...\n",
       "308    [ive, hear, lot, thorough, thing, simpang, asi...\n",
       "309    [would, decided, order, remember, ask, spicy, ...\n",
       "310    [theyre, constant, understaf, wait, can, get, ...\n",
       "311                             [crazy, juicy, overcook]\n",
       "312                                [little, annoy, rush]\n",
       "313             [bit, annoy, feel, rush, waitres, order]\n",
       "314              [dude, what, kid, theyre, freak, annoy]\n",
       "315    [many, small, bone, navigate, around, meat, al...\n",
       "316    [important, piece, information, friend, get, s...\n",
       "317    [thorough, want, eat, eat, get, sick, nutty, w...\n",
       "318    [whenever, sick, munch, innout, double, double...\n",
       "319    [overwhelm, majority, review, internet, articl...\n",
       "320    [one, server, man, phone, cash, register, seem...\n",
       "321    [menu, bit, confuse, overwhelm, someone, isnt,...\n",
       "322                                [nasty, nasty, nasty]\n",
       "323    [yeah, yeah, sound, nasty, ever, suck, cartila...\n",
       "324    [also, order, durian, smoothie, nasty, strange...\n",
       "325    [noooo, get, back, car, boyfriend, hesitant, b...\n",
       "326            [hide, gem, im, almost, hesitant, review]\n",
       "327    [order, nasi, goreng, jawa, maybe, im, weak, l...\n",
       "328            [hide, gem, im, almost, hesitant, review]\n",
       "Name: neg_sentence, Length: 329, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
